{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09839d26",
   "metadata": {},
   "source": [
    "This script produces JSON objects storing the splits between train / test / val for the three datasets that we have, based on geographic location. The approach is to (1) create a mapping based on basin ID in the label geojson and then (2) match the paths of files in the raw data directory with those in the IDs in the geojson. This is only possible because we named the scenes specifically for the lakes around which the download was centered.\n",
    "\n",
    "The main parameters are,\n",
    "* What directory contains all the Lake ID-named scenes?\n",
    "* What is the path to the geojson that contains the lake IDs and their sub-basins?\n",
    "* Which sub-basins should be assigned to which splits?\n",
    "* Where should we save the result?\n",
    "\n",
    "Note that I'm using sub-basins instead of basins, because I found that among the data we actually have downloaded, the number of scenes per basin are very highly skewed.\n",
    "\n",
    "To run this notebook with the different data sources, you can use (for example),\n",
    "\n",
    "Bing:\n",
    "\n",
    "```\n",
    "papermill -p in_dir /datadrive/glaciers/bing_glaciers/bing_glacial_lakes -p out_dir /datadrive/glaciers/bing_glaciers/bing_glacial_lakes/splits create_splits.ipynb -\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db518e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb89f73-a807-49f3-b59f-6c22db872641",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "in_dir = \"/datadrive/snake/lakes/le7-2015/\"\n",
    "label_path = \"/datadrive/snake/lakes/GL_3basins_2015.shp\"\n",
    "out_dir = \"/datadrive/snake/lakes/le7-2015/splits/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d06fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_mapping = {\n",
    "    \"train\": [\"Arun\", \"Bheri\", \"Budhi Gandaki\", \"Dudh Koshi\", \"Humla\", \"Indrawati\", \"Kali\", \"Kali Gandaki\"], \n",
    "    \"val\": [\"Karnali\", \"Kawari\", \"Likhu\", \"Marsyangdi\", \"Mugu\", \"Seti\"], \n",
    "    \"test\": [\"Sun Koshi\", \"Tama Koshi\", \"Tamor\", \"Tila\", \"Trishuli\", \"West Seti\"]\n",
    "}\n",
    "\n",
    "paths = {\"in\": Path(in_dir), \"label\": Path(label_path), \"out\": Path(out_dir)}\n",
    "if paths[\"out\"].exists():\n",
    "    shutil.rmtree(paths[\"out\"])\n",
    "\n",
    "for split in basin_mapping.keys():\n",
    "    (paths[\"out\"] / split).mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c9ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = gpd.read_file(paths[\"label\"])\n",
    "ids = {}\n",
    "for split in basin_mapping.keys():\n",
    "    ids[split] = list(y[y.Sub_Basin.isin(basin_mapping[split])].GL_ID.values)\n",
    "\n",
    "for path in paths[\"in\"].glob(\"*tif\"):\n",
    "    for split in ids.keys():\n",
    "        for i in ids[split]:\n",
    "            if path.stem.find(i) != -1:\n",
    "                shutil.copy2(path, paths[\"out\"] / split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
